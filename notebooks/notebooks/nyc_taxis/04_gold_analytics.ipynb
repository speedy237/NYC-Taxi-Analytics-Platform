{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6d3230-a72a-4bf7-95a0-b641f3dbbd0a",
   "metadata": {},
   "source": [
    "# Gold Layer - Analytics & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a62c558-be63-4984-b063-5c086b33257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/04_gold_analytics_ml.py\n",
    "\n",
    "print(\"üöÄ D√âMARRAGE DU PIPELINE GOLD - ANALYTICS & ML\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ============================================\n",
    "# FONCTIONS GOLD LAYER\n",
    "# ============================================\n",
    "\n",
    "def detect_silver_catalog():\n",
    "    \"\"\"D√©tecte automatiquement o√π sont les tables Silver\"\"\"\n",
    "    print(\"üîç D√©tection du catalogue Silver...\")\n",
    "    \n",
    "    for catalogue in [\"local\", \"iceberg\"]:\n",
    "        try:\n",
    "            tables = spark.sql(f\"SHOW TABLES IN {catalogue}.silver\").collect()\n",
    "            if tables and any(\"trips_complete\" in t.tableName for t in tables):\n",
    "                print(f\"   ‚úÖ Catalogue trouv√©: {catalogue}\")\n",
    "                return catalogue\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    raise Exception(\"‚ùå Aucune table Silver trouv√©e dans local.silver ni iceberg.silver\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ae8cf-7b78-4dac-826b-a9335c368d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_analytics_tables(silver_catalog):\n",
    "    \"\"\"\n",
    "    Cr√©er les tables analytiques Gold\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Cr√©ation des tables analytiques Gold...\")\n",
    "    \n",
    "    # Lire la table silver\n",
    "    trips_complete = spark.table(f\"{silver_catalog}.silver.trips_complete\")\n",
    "    \n",
    "    # Ajouter les colonnes manquantes\n",
    "    trips_complete = trips_complete.withColumn(\n",
    "        \"tip_percentage\",\n",
    "        F.when(F.col(\"total_amount\") > 0, (F.col(\"tip_amount\") / F.col(\"total_amount\")) * 100).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"pickup_hour\", F.hour(F.col(\"tpep_pickup_datetime\"))\n",
    "    ).withColumn(\n",
    "        \"pickup_date\", F.to_date(F.col(\"tpep_pickup_datetime\"))\n",
    "    )\n",
    "    \n",
    "    # ============================================\n",
    "    # 1. TABLE GOLD: DAILY METRICS\n",
    "    # ============================================\n",
    "    print(\"\\n   üìÖ Cr√©ation de daily_metrics...\")\n",
    "    \n",
    "    daily_metrics = trips_complete.groupBy(\n",
    "        \"pickup_date\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"total_trips\"),\n",
    "        F.sum(\"total_amount\").alias(\"daily_revenue\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_trip_distance\"),\n",
    "        F.avg(\"trip_duration_minutes\").alias(\"avg_trip_duration\"),\n",
    "        F.avg(\"passenger_count\").alias(\"avg_passenger_count\"),\n",
    "        F.sum(\"tip_amount\").alias(\"total_tips\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"),\n",
    "        F.countDistinct(\"VendorID\").alias(\"active_vendors\"),\n",
    "        F.sum(F.when(F.col(\"payment_type\") == 1, 1).otherwise(0)).alias(\"credit_card_trips\"),\n",
    "        F.sum(F.when(F.col(\"payment_type\") == 2, 1).otherwise(0)).alias(\"cash_trips\"),\n",
    "        F.sum(F.when(F.col(\"is_rainy\") == 1, 1).otherwise(0)).alias(\"rainy_trips\")\n",
    "    ).withColumn(\n",
    "        \"credit_card_percentage\",\n",
    "        (F.col(\"credit_card_trips\") / F.col(\"total_trips\")) * 100\n",
    "    ).withColumn(\n",
    "        \"revenue_per_trip\",\n",
    "        F.col(\"daily_revenue\") / F.col(\"total_trips\")\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"day_of_week\", F.dayofweek(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde\n",
    "    daily_metrics.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.daily_metrics\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.daily_metrics cr√©√©e: {daily_metrics.count():,} lignes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 2. TABLE GOLD: HOURLY PATTERNS\n",
    "    # ============================================\n",
    "    print(\"\\n   üïê Cr√©ation de hourly_patterns...\")\n",
    "    \n",
    "    hourly_patterns = trips_complete.groupBy(\n",
    "        \"pickup_date\",\n",
    "        \"pickup_hour\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"trip_count\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        F.avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        F.avg(\"speed_mph\").alias(\"avg_speed\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "        F.sum(F.when(F.col(\"is_weekend\") == 1, 1).otherwise(0)).alias(\"weekend_trips\"),\n",
    "        F.sum(F.when(F.col(\"is_weekend\") == 0, 1).otherwise(0)).alias(\"weekday_trips\")\n",
    "    ).withColumn(\n",
    "        \"hour_type\",\n",
    "        F.when((F.col(\"pickup_hour\") >= 6) & (F.col(\"pickup_hour\") <= 9), \"morning_rush\")\n",
    "        .when((F.col(\"pickup_hour\") >= 17) & (F.col(\"pickup_hour\") <= 20), \"evening_rush\")\n",
    "        .when((F.col(\"pickup_hour\") >= 22) | (F.col(\"pickup_hour\") <= 4), \"night\")\n",
    "        .otherwise(\"regular_hours\")\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde\n",
    "    hourly_patterns.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.hourly_patterns\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.hourly_patterns cr√©√©e: {hourly_patterns.count():,} lignes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 3. TABLE GOLD: TOP ROUTES\n",
    "    # ============================================\n",
    "    print(\"\\n   üó∫Ô∏è  Cr√©ation de top_routes...\")\n",
    "    \n",
    "    # Ajouter une colonne route_id pour identifier chaque route\n",
    "    trips_with_route = trips_complete.withColumn(\n",
    "        \"route_id\",\n",
    "        F.concat(F.col(\"PULocationID\"), F.lit(\"_\"), F.col(\"DOLocationID\"))\n",
    "    )\n",
    "    \n",
    "    top_routes = trips_with_route.groupBy(\n",
    "        \"route_id\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"pickup_date\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"trip_count\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        F.avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        F.avg(\"speed_mph\").alias(\"avg_speed\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "        F.sum(\"passenger_count\").alias(\"total_passengers\")\n",
    "    ).withColumn(\n",
    "        \"efficiency_ratio\",\n",
    "        F.col(\"avg_distance\") / F.when(F.col(\"avg_duration\") > 0, F.col(\"avg_duration\")).otherwise(1)\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    ).orderBy(\n",
    "        F.desc(\"trip_count\")\n",
    "    ).limit(1000)  # Limiter aux 1000 routes les plus fr√©quentes\n",
    "    \n",
    "    # Sauvegarde\n",
    "    top_routes.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.top_routes\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.top_routes cr√©√©e: {top_routes.count():,} lignes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 4. TABLE GOLD: DRIVER PERFORMANCE METRICS\n",
    "    # ============================================\n",
    "    print(\"\\n   üöï Cr√©ation de driver_performance...\")\n",
    "    \n",
    "    driver_performance = trips_complete.groupBy(\n",
    "        \"VendorID\",\n",
    "        \"pickup_date\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"trips_completed\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"trip_duration_minutes\").alias(\"avg_trip_duration\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        F.avg(\"speed_mph\").alias(\"avg_speed\"),\n",
    "        F.sum(\"tip_amount\").alias(\"total_tips\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_percentage\"),\n",
    "        F.sum(F.when(F.col(\"payment_type\") == 1, 1).otherwise(0)).alias(\"credit_card_trips\"),\n",
    "        F.sum(F.when(F.col(\"payment_type\") == 2, 1).otherwise(0)).alias(\"cash_trips\")\n",
    "    ).withColumn(\n",
    "        \"revenue_per_hour\",\n",
    "        F.when(F.col(\"avg_trip_duration\") > 0,\n",
    "               F.col(\"total_revenue\") / (F.col(\"avg_trip_duration\") * F.col(\"trips_completed\") / 60))\n",
    "        .otherwise(None)\n",
    "    ).withColumn(\n",
    "        \"credit_card_percentage\",\n",
    "        (F.col(\"credit_card_trips\") / F.col(\"trips_completed\")) * 100\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde\n",
    "    driver_performance.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.driver_performance\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.driver_performance cr√©√©e: {driver_performance.count():,} lignes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 5. TABLE GOLD: WEATHER IMPACT ANALYSIS\n",
    "    # ============================================\n",
    "    print(\"\\n   üå§Ô∏è  Cr√©ation de weather_impact...\")\n",
    "    \n",
    "    weather_impact = trips_complete.groupBy(\n",
    "        \"pickup_date\",\n",
    "        \"is_rainy\",\n",
    "        \"is_cold\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"total_trips\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        F.avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        F.avg(\"speed_mph\").alias(\"avg_speed\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "        F.avg(\"temperature\").alias(\"avg_temperature\")\n",
    "    ).withColumn(\n",
    "        \"weather_condition\",\n",
    "        F.when((F.col(\"is_rainy\") == 1) & (F.col(\"is_cold\") == 1), \"rainy_cold\")\n",
    "        .when((F.col(\"is_rainy\") == 1) & (F.col(\"is_cold\") == 0), \"rainy_warm\")\n",
    "        .when((F.col(\"is_rainy\") == 0) & (F.col(\"is_cold\") == 1), \"dry_cold\")\n",
    "        .otherwise(\"dry_warm\")\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde\n",
    "    weather_impact.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.weather_impact\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.weather_impact cr√©√©e: {weather_impact.count():,} lignes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 6. TABLE GOLD: PAYMENT ANALYSIS\n",
    "    # ============================================\n",
    "    print(\"\\n   üí≥ Cr√©ation de payment_analysis...\")\n",
    "    \n",
    "    payment_analysis = trips_complete.groupBy(\n",
    "        \"pickup_date\",\n",
    "        \"payment_type\"\n",
    "    ).agg(\n",
    "        F.count(\"*\").alias(\"trip_count\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_fare\"),\n",
    "        F.sum(\"tip_amount\").alias(\"total_tips\"),\n",
    "        F.avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\")\n",
    "    ).withColumn(\n",
    "        \"payment_type_label\",\n",
    "        F.when(F.col(\"payment_type\") == 1, \"credit_card\")\n",
    "        .when(F.col(\"payment_type\") == 2, \"cash\")\n",
    "        .when(F.col(\"payment_type\") == 3, \"no_charge\")\n",
    "        .when(F.col(\"payment_type\") == 4, \"dispute\")\n",
    "        .when(F.col(\"payment_type\") == 5, \"unknown\")\n",
    "        .when(F.col(\"payment_type\") == 6, \"voided\")\n",
    "        .otherwise(\"other\")\n",
    "    ).withColumn(\n",
    "        \"year\", F.year(\"pickup_date\")\n",
    "    ).withColumn(\n",
    "        \"month\", F.month(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde\n",
    "    payment_analysis.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.payment_analysis\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Table gold.payment_analysis cr√©√©e: {payment_analysis.count():,} lignes\")\n",
    "    \n",
    "    return daily_metrics, hourly_patterns, top_routes, driver_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947abd76-ecce-4c2a-8fa5-fddc43f13f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_features_dataset(silver_catalog):\n",
    "    \"\"\"\n",
    "    Cr√©er un dataset de features pour le machine learning\n",
    "    \"\"\"\n",
    "    print(\"\\nü§ñ √âtape 2: Cr√©ation du dataset ML features...\")\n",
    "    \n",
    "    # Lire la table silver compl√®te\n",
    "    trips_complete = spark.table(f\"{silver_catalog}.silver.trips_complete\")\n",
    "    \n",
    "    # Afficher le nombre total de lignes\n",
    "    total_count = trips_complete.count()\n",
    "    print(f\"   Donn√©es totales: {total_count:,} lignes\")\n",
    "    \n",
    "    # Prendre un √©chantillon pour le ML (10% des donn√©es)\n",
    "    ml_sample = trips_complete.sample(fraction=0.1, seed=42)\n",
    "    sample_count = ml_sample.count()\n",
    "    print(f\"   √âchantillon ML: {sample_count:,} lignes (10% des donn√©es)\")\n",
    "    \n",
    "    # Cr√©er les colonnes temporelles n√©cessaires\n",
    "    ml_sample = ml_sample.withColumn(\n",
    "        \"pickup_date\", F.to_date(F.col(\"tpep_pickup_datetime\"))\n",
    "    ).withColumn(\n",
    "        \"hour_of_day\", F.hour(F.col(\"tpep_pickup_datetime\"))\n",
    "    ).withColumn(\n",
    "        \"day_of_week\", F.dayofweek(F.col(\"tpep_pickup_datetime\"))\n",
    "    ).withColumn(\n",
    "        \"pickup_month\", F.month(F.col(\"tpep_pickup_datetime\"))\n",
    "    ).withColumn(\n",
    "        \"pickup_year\", F.year(F.col(\"tpep_pickup_datetime\"))\n",
    "    )\n",
    "    \n",
    "    print(\"\\n   üîß Feature engineering avanc√©...\")\n",
    "    \n",
    "    # 1. Features temporelles cycliques (sin/cos)\n",
    "    ml_features = ml_sample.withColumn(\n",
    "        \"hour_sin\", F.sin(2 * np.pi * F.col(\"hour_of_day\") / 24)\n",
    "    ).withColumn(\n",
    "        \"hour_cos\", F.cos(2 * np.pi * F.col(\"hour_of_day\") / 24)\n",
    "    ).withColumn(\n",
    "        \"day_sin\", F.sin(2 * np.pi * (F.col(\"day_of_week\") - 1) / 7)  # -1 pour commencer √† 0\n",
    "    ).withColumn(\n",
    "        \"day_cos\", F.cos(2 * np.pi * (F.col(\"day_of_week\") - 1) / 7)  # -1 pour commencer √† 0\n",
    "    ).withColumn(\n",
    "        \"month_sin\", F.sin(2 * np.pi * F.col(\"pickup_month\") / 12)\n",
    "    ).withColumn(\n",
    "        \"month_cos\", F.cos(2 * np.pi * F.col(\"pickup_month\") / 12)\n",
    "    )\n",
    "    \n",
    "    # 2. Features de trafic (agr√©gations glissantes)\n",
    "    # D'abord, cr√©er une colonne de timestamp pour le window\n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"pickup_timestamp\", F.unix_timestamp(F.col(\"tpep_pickup_datetime\"))\n",
    "    )\n",
    "    \n",
    "    # D√©finir la fen√™tre temporelle (3 heures avant le trajet actuel)\n",
    "    window_spec = Window.partitionBy(\"PULocationID\").orderBy(\"pickup_timestamp\").rangeBetween(-3*3600, -1)\n",
    "    \n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"recent_trips_in_area\",\n",
    "        F.count(\"*\").over(window_spec)\n",
    "    ).withColumn(\n",
    "        \"avg_recent_fare_in_area\",\n",
    "        F.avg(\"total_amount\").over(window_spec)\n",
    "    )\n",
    "    \n",
    "    # 3. Features de distance et vitesse\n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"log_trip_distance\", F.log1p(F.col(\"trip_distance\"))\n",
    "    ).withColumn(\n",
    "        \"log_trip_duration\", F.log1p(F.col(\"trip_duration_minutes\"))\n",
    "    ).withColumn(\n",
    "        \"distance_duration_ratio\",\n",
    "        F.col(\"trip_distance\") / F.when(F.col(\"trip_duration_minutes\") > 0, F.col(\"trip_duration_minutes\")).otherwise(1)\n",
    "    )\n",
    "    \n",
    "    # 4. Features m√©t√©orologiques avanc√©es\n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"rainy_cold\", F.when((F.col(\"is_rainy\") == 1) & (F.col(\"is_cold\") == 1), 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"rainy_warm\", F.when((F.col(\"is_rainy\") == 1) & (F.col(\"is_cold\") == 0), 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"dry_cold\", F.when((F.col(\"is_rainy\") == 0) & (F.col(\"is_cold\") == 1), 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"dry_warm\", F.when((F.col(\"is_rainy\") == 0) & (F.col(\"is_cold\") == 0), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 5. Features de localisation (hot encoding simplifi√© des zones les plus fr√©quentes)\n",
    "    # Identifier les 20 zones de pickup les plus fr√©quentes\n",
    "    top_pickup_zones = trips_complete.groupBy(\"PULocationID\").count().orderBy(F.desc(\"count\")).limit(20)\n",
    "    top_pickup_zones_list = [row[\"PULocationID\"] for row in top_pickup_zones.collect()]\n",
    "    \n",
    "    for i, zone_id in enumerate(top_pickup_zones_list[:10]):  # Limiter aux 10 premi√®res pour √©viter trop de colonnes\n",
    "        ml_features = ml_features.withColumn(\n",
    "            f\"pickup_zone_{zone_id}\",\n",
    "            F.when(F.col(\"PULocationID\") == zone_id, 1).otherwise(0)\n",
    "        )\n",
    "    \n",
    "    # 6. Features de type de jour\n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"is_morning_rush\", \n",
    "        F.when((F.col(\"hour_of_day\") >= 6) & (F.col(\"hour_of_day\") <= 9), 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"is_evening_rush\", \n",
    "        F.when((F.col(\"hour_of_day\") >= 17) & (F.col(\"hour_of_day\") <= 20), 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"is_night\", \n",
    "        F.when((F.col(\"hour_of_day\") >= 22) | (F.col(\"hour_of_day\") <= 4), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 7. Features de prix et pourboire\n",
    "    ml_features = ml_features.withColumn(\n",
    "        \"fare_per_mile\",\n",
    "        F.when(F.col(\"trip_distance\") > 0, F.col(\"fare_amount\") / F.col(\"trip_distance\")).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"tip_percentage\",\n",
    "        F.when(F.col(\"total_amount\") > 0, (F.col(\"tip_amount\") / F.col(\"total_amount\")) * 100).otherwise(0)\n",
    "    ).withColumn(\n",
    "        \"has_tip\",\n",
    "        F.when(F.col(\"tip_amount\") > 0, 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # S√©lectionner les colonnes finales pour le dataset ML\n",
    "    # Note: Nous √©vitons les duplications de colonnes\n",
    "    ml_dataset = ml_features.select(\n",
    "        # Identifiants et timestamps\n",
    "        \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"pickup_date\",\n",
    "        \n",
    "        # Features de base\n",
    "        \"passenger_count\", \"trip_distance\", \"PULocationID\", \"DOLocationID\", \n",
    "        \"payment_type\", \"fare_amount\", \"tip_amount\", \"total_amount\",\n",
    "        \n",
    "        # Features calcul√©es Silver\n",
    "        \"trip_duration_minutes\", \"speed_mph\", \"is_weekend\", \"is_rainy\", \n",
    "        \"is_cold\", \"is_hot\", \"temperature\", \"precipitation\",\n",
    "        \n",
    "        # Features temporelles\n",
    "        \"hour_of_day\", \"day_of_week\", \"pickup_month\", \"pickup_year\",\n",
    "        \n",
    "        # Features cycliques\n",
    "        \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\",\n",
    "        \n",
    "        # Features de trafic\n",
    "        \"recent_trips_in_area\", \"avg_recent_fare_in_area\",\n",
    "        \n",
    "        # Features de distance/vitesse\n",
    "        \"log_trip_distance\", \"log_trip_duration\", \"distance_duration_ratio\",\n",
    "        \n",
    "        # Features m√©t√©o avanc√©es\n",
    "        \"rainy_cold\", \"rainy_warm\", \"dry_cold\", \"dry_warm\",\n",
    "        \n",
    "        # Features de type de jour\n",
    "        \"is_morning_rush\", \"is_evening_rush\", \"is_night\",\n",
    "        \n",
    "        # Features de prix\n",
    "        \"fare_per_mile\", \"tip_percentage\", \"has_tip\"\n",
    "        \n",
    "        # Note: Nous avons retir√© les colonnes en double:\n",
    "        # \"trip_duration_minutes\", \"total_amount\", \"tip_amount\" √©taient d√©j√† incluses\n",
    "        # dans les sections pr√©c√©dentes\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder le dataset ML\n",
    "    ml_dataset.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.ml_dataset\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Dataset ML cr√©√©: {ml_dataset.count():,} lignes\")\n",
    "    print(f\"   üìä Nombre de features: {len(ml_dataset.columns)}\")\n",
    "    \n",
    "    # Afficher un √©chantillon des features\n",
    "    print(\"\\n   üìã Aper√ßu des features cr√©√©es:\")\n",
    "    ml_dataset.limit(5).show()\n",
    "    \n",
    "    return ml_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d9c71-9576-4818-9e91-66cfbcab767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_training_datasets(silver_catalog):\n",
    "    \"\"\"\n",
    "    Pr√©pare des datasets sp√©cifiques pour diff√©rents probl√®mes ML\n",
    "    \"\"\"\n",
    "    print(\"\\nüéØ √âtape 3: Pr√©paration des datasets d'entra√Ænement ML...\")\n",
    "    \n",
    "    # Lire le dataset ML que nous venons de cr√©er\n",
    "    ml_features = spark.table(f\"{silver_catalog}.gold.ml_dataset\")\n",
    "    \n",
    "    # 1. DATASET: Pr√©diction du prix\n",
    "    print(\"\\n   1. Dataset: Pr√©diction du prix (regression)...\")\n",
    "    \n",
    "    fare_features = ml_features.select(\n",
    "        # Features temporelles\n",
    "        \"hour_of_day\", \"day_of_week\", \"pickup_month\", \"pickup_year\",\n",
    "        \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\",\n",
    "        \n",
    "        # Features de localisation\n",
    "        \"PULocationID\", \"DOLocationID\",\n",
    "        \n",
    "        # Features de trajet\n",
    "        \"passenger_count\", \"trip_distance\", \"trip_duration_minutes\",\n",
    "        \n",
    "        # Features m√©t√©o\n",
    "        \"is_rainy\", \"is_cold\", \"is_hot\", \"temperature\", \"precipitation\",\n",
    "        \"rainy_cold\", \"rainy_warm\", \"dry_cold\", \"dry_warm\",\n",
    "        \n",
    "        # Features de trafic\n",
    "        \"recent_trips_in_area\", \"avg_recent_fare_in_area\",\n",
    "        \n",
    "        # Features de type de jour\n",
    "        \"is_morning_rush\", \"is_evening_rush\", \"is_night\",\n",
    "        \n",
    "        # Features calcul√©es\n",
    "        \"log_trip_distance\", \"log_trip_duration\", \"distance_duration_ratio\",\n",
    "        \"fare_per_mile\",\n",
    "        \n",
    "        # Features du week-end\n",
    "        \"is_weekend\",\n",
    "        \n",
    "        # Target variable\n",
    "        \"total_amount\"\n",
    "    ).filter(\n",
    "        (F.col(\"total_amount\") > 0) & \n",
    "        (F.col(\"total_amount\") < 500)  # Filtrer les valeurs extr√™mes\n",
    "    )\n",
    "    \n",
    "    # 2. DATASET: Pr√©diction de la dur√©e\n",
    "    print(\"\\n   2. Dataset: Pr√©diction de la dur√©e (regression)...\")\n",
    "    \n",
    "    duration_features = ml_features.select(\n",
    "        # Features temporelles\n",
    "        \"hour_of_day\", \"day_of_week\", \"pickup_month\",\n",
    "        \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\",\n",
    "        \n",
    "        # Features de localisation\n",
    "        \"PULocationID\", \"DOLocationID\",\n",
    "        \n",
    "        # Features de trajet\n",
    "        \"passenger_count\", \"trip_distance\",\n",
    "        \n",
    "        # Features m√©t√©o\n",
    "        \"is_rainy\", \"is_cold\", \"is_hot\", \"temperature\", \"precipitation\",\n",
    "        \"rainy_cold\", \"rainy_warm\", \"dry_cold\", \"dry_warm\",\n",
    "        \n",
    "        # Features de trafic\n",
    "        \"recent_trips_in_area\", \"avg_recent_fare_in_area\",\n",
    "        \n",
    "        # Features de type de jour\n",
    "        \"is_morning_rush\", \"is_evening_rush\", \"is_night\",\n",
    "        \n",
    "        # Features calcul√©es\n",
    "        \"log_trip_distance\", \"distance_duration_ratio\",\n",
    "        \n",
    "        # Features du week-end\n",
    "        \"is_weekend\",\n",
    "        \n",
    "        # Target variable\n",
    "        \"trip_duration_minutes\"\n",
    "    ).filter(\n",
    "        (F.col(\"trip_duration_minutes\") > 0) & \n",
    "        (F.col(\"trip_duration_minutes\") < 180)  # Filtrer les trajets de plus de 3 heures\n",
    "    )\n",
    "    \n",
    "    # 3. DATASET: Pr√©diction du pourboire (classification)\n",
    "    print(\"\\n   3. Dataset: Pr√©diction du pourboire (classification)...\")\n",
    "    \n",
    "    tip_features = ml_features.select(\n",
    "        # Features temporelles\n",
    "        \"hour_of_day\", \"day_of_week\", \"pickup_month\",\n",
    "        \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\",\n",
    "        \n",
    "        # Features de localisation\n",
    "        \"PULocationID\", \"DOLocationID\",\n",
    "        \n",
    "        # Features de trajet\n",
    "        \"passenger_count\", \"trip_distance\", \"trip_duration_minutes\",\n",
    "        \n",
    "        # Features de paiement\n",
    "        \"payment_type\", \"fare_amount\", \"total_amount\",\n",
    "        \n",
    "        # Features m√©t√©o\n",
    "        \"is_rainy\", \"is_cold\", \"is_hot\", \"temperature\", \"precipitation\",\n",
    "        \"rainy_cold\", \"rainy_warm\", \"dry_cold\", \"dry_warm\",\n",
    "        \n",
    "        # Features de trafic\n",
    "        \"recent_trips_in_area\", \"avg_recent_fare_in_area\",\n",
    "        \n",
    "        # Features de type de jour\n",
    "        \"is_morning_rush\", \"is_evening_rush\", \"is_night\",\n",
    "        \n",
    "        # Features calcul√©es\n",
    "        \"log_trip_distance\", \"log_trip_duration\", \"distance_duration_ratio\",\n",
    "        \"fare_per_mile\", \"tip_percentage\",\n",
    "        \n",
    "        # Features du week-end\n",
    "        \"is_weekend\",\n",
    "        \n",
    "        # Target variable (classification binaire: pourboire ou non)\n",
    "        \"has_tip\"\n",
    "    ).filter(\n",
    "        F.col(\"payment_type\").isin([1, 2])  # Seulement les paiements par carte de cr√©dit ou esp√®ces\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder les datasets\n",
    "    fare_features.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.ml_fare_prediction\")\n",
    "    \n",
    "    duration_features.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.ml_duration_prediction\")\n",
    "    \n",
    "    tip_features.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.ml_tip_prediction\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Dataset prix cr√©√©: {fare_features.count():,} lignes\")\n",
    "    print(f\"   ‚úÖ Dataset dur√©e cr√©√©: {duration_features.count():,} lignes\")\n",
    "    print(f\"   ‚úÖ Dataset pourboire cr√©√©: {tip_features.count():,} lignes\")\n",
    "    \n",
    "    return fare_features, duration_features, tip_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576eb5c-c8be-4604-aa47-00b85c1f594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_superset_views(silver_catalog):\n",
    "    \"\"\"\n",
    "    Cr√©er des tables sp√©cifiques pour les dashboards Superset/Tableau\n",
    "    (Adapt√© pour cr√©er des tables au lieu de vues car Iceberg ne supporte pas les vues)\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä √âtape 4: Cr√©ation des tables pour dashboards...\")\n",
    "    \n",
    "    # 1. TABLE: Executive Dashboard\n",
    "    print(\"\\n   1. Table: executive_dashboard...\")\n",
    "    \n",
    "    # Lire la table daily_metrics et ajouter des calculs suppl√©mentaires\n",
    "    daily_data = spark.table(f\"{silver_catalog}.gold.daily_metrics\")\n",
    "    \n",
    "    # D√©finir une fen√™tre pour les calculs de moyenne mobile et de croissance, partitionn√©e par ann√©e\n",
    "    window_spec_7d = Window.partitionBy(\"year\").orderBy(\"pickup_date\").rowsBetween(-6, 0)\n",
    "    window_spec_lag = Window.partitionBy(\"year\").orderBy(\"pickup_date\")\n",
    "    \n",
    "    executive_dashboard = daily_data.select(\n",
    "        \"pickup_date\", \"year\", \"month\", \"day_of_week\",\n",
    "        \"total_trips\", \"daily_revenue\", \"revenue_per_trip\",\n",
    "        \"avg_trip_distance\", \"avg_trip_duration\", \"avg_passenger_count\",\n",
    "        \"total_tips\", \"avg_tip_percentage\", \"active_vendors\",\n",
    "        \"credit_card_percentage\", \"rainy_trips\",\n",
    "        F.when(F.col(\"day_of_week\").isin([1, 7]), \"Weekend\")\n",
    "         .otherwise(\"Weekday\").alias(\"weekday_type\")\n",
    "    ).withColumn(\n",
    "        \"rolling_avg_trips_7d\",\n",
    "        F.avg(\"total_trips\").over(window_spec_7d)\n",
    "    ).withColumn(\n",
    "        \"rolling_avg_revenue_7d\",\n",
    "        F.avg(\"daily_revenue\").over(window_spec_7d)\n",
    "    ).withColumn(\n",
    "        \"revenue_growth\",\n",
    "        ((F.col(\"daily_revenue\") - F.lag(\"daily_revenue\", 1).over(window_spec_lag)) /\n",
    "         F.lag(\"daily_revenue\", 1).over(window_spec_lag)) * 100\n",
    "    ).withColumn(\n",
    "        \"quarter\",\n",
    "        F.quarter(\"pickup_date\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    executive_dashboard.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.executive_dashboard\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table executive_dashboard cr√©√©e\")\n",
    "    \n",
    "    # 2. TABLE: Hourly Analysis\n",
    "    print(\"\\n   2. Table: hourly_analysis...\")\n",
    "    \n",
    "    hourly_data = spark.table(f\"{silver_catalog}.gold.hourly_patterns\")\n",
    "    \n",
    "    hourly_analysis = hourly_data.select(\n",
    "        \"pickup_date\", \"pickup_hour\", \"year\", \"month\",\n",
    "        \"trip_count\", \"avg_distance\", \"avg_duration\", \"avg_fare\",\n",
    "        \"avg_speed\", \"avg_tip_pct\", \"hour_type\",\n",
    "        F.col(\"weekend_trips\").alias(\"weekend_trip_count\"),\n",
    "        F.col(\"weekday_trips\").alias(\"weekday_trip_count\"),\n",
    "        (F.col(\"weekend_trips\") / F.col(\"trip_count\") * 100).alias(\"weekend_percentage\")\n",
    "    ).withColumn(\n",
    "        \"hour_of_day_category\",\n",
    "        F.when(F.col(\"pickup_hour\").between(0, 5), \"Night (0-5)\")\n",
    "         .when(F.col(\"pickup_hour\").between(6, 9), \"Morning Rush (6-9)\")\n",
    "         .when(F.col(\"pickup_hour\").between(10, 15), \"Midday (10-15)\")\n",
    "         .when(F.col(\"pickup_hour\").between(16, 19), \"Evening Rush (16-19)\")\n",
    "         .otherwise(\"Late Evening (20-23)\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    hourly_analysis.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.hourly_analysis\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table hourly_analysis cr√©√©e\")\n",
    "    \n",
    "    # 3. TABLE: Driver Analytics\n",
    "    print(\"\\n   3. Table: driver_analytics...\")\n",
    "    \n",
    "    driver_data = spark.table(f\"{silver_catalog}.gold.driver_performance\")\n",
    "    \n",
    "    # D√©finir une fen√™tre pour les calculs de score d'efficacit√©\n",
    "    # Nous partitionnons par ann√©e et mois pour que les calculs soient faits par p√©riode\n",
    "    window_spec_driver = Window.partitionBy(\"year\", \"month\")\n",
    "    \n",
    "    driver_analytics = driver_data.select(\n",
    "        \"VendorID\", \"pickup_date\", \"year\", \"month\",\n",
    "        \"trips_completed\", \"total_revenue\", \"revenue_per_hour\",\n",
    "        \"avg_trip_duration\", \"avg_fare\", \"avg_speed\",\n",
    "        \"total_tips\", \"avg_tip_percentage\", \"credit_card_percentage\"\n",
    "    ).withColumn(\n",
    "        \"driver_efficiency_score\",\n",
    "        ((F.col(\"revenue_per_hour\") / F.avg(\"revenue_per_hour\").over(window_spec_driver)) * 100).cast(\"decimal(10,2)\")\n",
    "    ).withColumn(\n",
    "        \"driver_tier\",\n",
    "        F.when(F.col(\"revenue_per_hour\") >= F.percentile_approx(\"revenue_per_hour\", 0.8).over(window_spec_driver), \"Premium\")\n",
    "         .when(F.col(\"revenue_per_hour\") >= F.percentile_approx(\"revenue_per_hour\", 0.5).over(window_spec_driver), \"Gold\")\n",
    "         .otherwise(\"Silver\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    driver_analytics.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.driver_analytics\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table driver_analytics cr√©√©e\")\n",
    "    \n",
    "    # 4. TABLE: Weather Impact Dashboard\n",
    "    print(\"\\n   4. Table: weather_dashboard...\")\n",
    "    \n",
    "    weather_data = spark.table(f\"{silver_catalog}.gold.weather_impact\")\n",
    "    \n",
    "    weather_dashboard = weather_data.select(\n",
    "        \"pickup_date\", \"year\", \"month\",\n",
    "        \"weather_condition\", \"avg_temperature\", \"total_trips\",\n",
    "        \"avg_distance\", \"avg_duration\", \"avg_fare\",\n",
    "        \"avg_speed\", \"avg_tip_pct\"\n",
    "    ).withColumn(\n",
    "        \"temperature_range\",\n",
    "        F.when(F.col(\"avg_temperature\") < 0, \"Very Cold (<0¬∞C)\")\n",
    "         .when(F.col(\"avg_temperature\").between(0, 10), \"Cold (0-10¬∞C)\")\n",
    "         .when(F.col(\"avg_temperature\").between(11, 20), \"Cool (11-20¬∞C)\")\n",
    "         .when(F.col(\"avg_temperature\").between(21, 30), \"Warm (21-30¬∞C)\")\n",
    "         .otherwise(\"Hot (>30¬∞C)\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    weather_dashboard.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.weather_dashboard\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table weather_dashboard cr√©√©e\")\n",
    "    \n",
    "    # 5. TABLE: Route Analysis\n",
    "    print(\"\\n   5. Table: route_analysis...\")\n",
    "    \n",
    "    route_data = spark.table(f\"{silver_catalog}.gold.top_routes\")\n",
    "    \n",
    "    # D√©finir une fen√™tre pour le classement de popularit√©\n",
    "    window_spec_route = Window.partitionBy(\"pickup_date\").orderBy(F.desc(\"trip_count\"))\n",
    "    \n",
    "    route_analysis = route_data.select(\n",
    "        \"route_id\", \"PULocationID\", \"DOLocationID\", \"pickup_date\", \"year\", \"month\",\n",
    "        \"trip_count\", \"avg_distance\", \"avg_duration\", \"avg_fare\",\n",
    "        \"avg_speed\", \"avg_tip_pct\", \"total_passengers\", \"efficiency_ratio\"\n",
    "    ).withColumn(\n",
    "        \"popularity_rank\",\n",
    "        F.row_number().over(window_spec_route)\n",
    "    ).withColumn(\n",
    "        \"route_type\",\n",
    "        F.when(F.col(\"avg_distance\") < 1, \"Short (<1 mi)\")\n",
    "         .when(F.col(\"avg_distance\").between(1, 5), \"Medium (1-5 mi)\")\n",
    "         .when(F.col(\"avg_distance\").between(5, 10), \"Long (5-10 mi)\")\n",
    "         .otherwise(\"Very Long (>10 mi)\")\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    route_analysis.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.route_analysis\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table route_analysis cr√©√©e\")\n",
    "    \n",
    "    # 6. TABLE: Payment Analytics\n",
    "    print(\"\\n   6. Table: payment_dashboard...\")\n",
    "    \n",
    "    payment_data = spark.table(f\"{silver_catalog}.gold.payment_analysis\")\n",
    "    \n",
    "    # D√©finir une fen√™tre pour les calculs de part de march√©\n",
    "    window_spec_payment = Window.partitionBy(\"pickup_date\")\n",
    "    \n",
    "    payment_dashboard = payment_data.select(\n",
    "        \"pickup_date\", \"payment_type\", \"payment_type_label\", \"year\", \"month\",\n",
    "        \"trip_count\", \"total_revenue\", \"avg_fare\", \"total_tips\", \"avg_tip_pct\", \"avg_distance\"\n",
    "    ).withColumn(\n",
    "        \"market_share\",\n",
    "        (F.col(\"trip_count\") / F.sum(\"trip_count\").over(window_spec_payment)) * 100\n",
    "    ).withColumn(\n",
    "        \"revenue_share\",\n",
    "        (F.col(\"total_revenue\") / F.sum(\"total_revenue\").over(window_spec_payment)) * 100\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder en tant que table\n",
    "    payment_dashboard.write \\\n",
    "        .format(\"iceberg\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"year\", \"month\") \\\n",
    "        .saveAsTable(f\"{silver_catalog}.gold.payment_dashboard\")\n",
    "    \n",
    "    print(\"      ‚úÖ Table payment_dashboard cr√©√©e\")\n",
    "    \n",
    "    print(\"\\n   üéØ Toutes les tables dashboard ont √©t√© cr√©√©es!\")\n",
    "    print(\"      ‚Ä¢ executive_dashboard\")\n",
    "    print(\"      ‚Ä¢ hourly_analysis\") \n",
    "    print(\"      ‚Ä¢ driver_analytics\")\n",
    "    print(\"      ‚Ä¢ weather_dashboard\")\n",
    "    print(\"      ‚Ä¢ route_analysis\")\n",
    "    print(\"      ‚Ä¢ payment_dashboard\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4eae1-c1cb-415b-ba15-a022ff152a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gold_data_quality_checks(silver_catalog):\n",
    "    \"\"\"\n",
    "    Ex√©cute des v√©rifications de qualit√© pour le Gold Layer\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç √âtape 5: V√©rification de la qualit√© des donn√©es Gold...\")\n",
    "    \n",
    "    quality_checks = []\n",
    "    \n",
    "    # V√©rifier que les tables Gold existent\n",
    "    gold_tables = [\n",
    "        \"daily_business_metrics\",\n",
    "        \"hourly_patterns\", \n",
    "        \"top_routes\",\n",
    "        \"driver_performance\",\n",
    "        \"ml_tip_prediction\"\n",
    "    ]\n",
    "    \n",
    "    for table in gold_tables:\n",
    "        try:\n",
    "            count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {silver_catalog}.gold.{table}\").collect()[0]['cnt']\n",
    "            quality_checks.append((f\"Table {table} existe\", count > 0))\n",
    "        except:\n",
    "            quality_checks.append((f\"Table {table} existe\", False))\n",
    "    \n",
    "    # V√©rifications sp√©cifiques\n",
    "    try:\n",
    "        # V√©rifier les m√©triques quotidiennes\n",
    "        daily_stats = spark.table(f\"{silver_catalog}.gold.daily_business_metrics\")\n",
    "        avg_trips = daily_stats.select(F.avg(\"total_trips\")).collect()[0][0]\n",
    "        quality_checks.append((\"M√©triques quotidiennes coh√©rentes\", avg_trips > 0))\n",
    "    except:\n",
    "        quality_checks.append((\"M√©triques quotidiennes coh√©rentes\", False))\n",
    "    \n",
    "    # Afficher les r√©sultats\n",
    "    passed = 0\n",
    "    total = len(quality_checks)\n",
    "    \n",
    "    for check_name, check_result in quality_checks:\n",
    "        if check_result:\n",
    "            print(f\"   ‚úÖ {check_name}\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"   ‚ùå {check_name}\")\n",
    "    \n",
    "    print(f\"\\nüìä R√©sum√© qualit√© Gold: {passed}/{total} checks pass√©s\")\n",
    "    \n",
    "    return passed == total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711cb47-901f-4c43-8ef0-4550a02fb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_namespace(silver_catalog):\n",
    "    \"\"\"\n",
    "    Cr√©er ou valider le namespace (base de donn√©es) pour le layer Gold\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìÅ Catalogue Silver d√©tect√©: {silver_catalog}\")\n",
    "    \n",
    "    # Nom du namespace Gold\n",
    "    gold_namespace = f\"{silver_catalog}.gold\"\n",
    "    \n",
    "    try:\n",
    "        # V√©rifier si le namespace existe d√©j√†\n",
    "        spark.sql(f\"SHOW NAMESPACES IN {silver_catalog}\")\n",
    "        namespaces = [row.namespace for row in spark.sql(f\"SHOW NAMESPACES IN {silver_catalog}\").collect()]\n",
    "        \n",
    "        if \"gold\" in namespaces:\n",
    "            print(f\"‚ÑπÔ∏è  Namespace {gold_namespace} d√©j√† existant\")\n",
    "        else:\n",
    "            # Cr√©er le namespace Gold\n",
    "            spark.sql(f\"CREATE NAMESPACE {gold_namespace}\")\n",
    "            print(f\"‚úÖ Namespace {gold_namespace} cr√©√©\")\n",
    "    except Exception as e:\n",
    "        # Si la commande SHOW NAMESPACES √©choue, essayer de cr√©er directement\n",
    "        try:\n",
    "            spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {gold_namespace}\")\n",
    "            print(f\"‚úÖ Namespace {gold_namespace} cr√©√©/valid√©\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ö†Ô∏è  Impossible de cr√©er le namespace: {e2}\")\n",
    "            print(f\"‚ÑπÔ∏è  Utilisation du namespace par d√©faut\")\n",
    "    \n",
    "    return gold_namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bbc03-f94a-40d8-b2c9-c5b02e20808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ex√©cute le pipeline Gold complet\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ D√âMARRAGE DU PIPELINE GOLD - ANALYTICS & ML\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # 1. D√©tecter le catalogue Silver\n",
    "        silver_catalog = detect_silver_catalog()\n",
    "        \n",
    "        # 2. Cr√©er/valider le namespace Gold\n",
    "        create_gold_namespace(silver_catalog)\n",
    "        \n",
    "        # 3. Cr√©er les tables analytiques\n",
    "        daily_metrics, hourly_patterns, top_routes, driver_performance = create_gold_analytics_tables(silver_catalog)\n",
    "        \n",
    "        # 4. Cr√©er les features ML\n",
    "        ml_dataset = create_ml_features_dataset(silver_catalog)\n",
    "        \n",
    "        # 5. Pr√©parer les datasets d'entra√Ænement\n",
    "        fare_df, duration_df, tip_df = prepare_ml_training_datasets(silver_catalog)\n",
    "        \n",
    "        # 6. Cr√©er les tables pour dashboards\n",
    "        create_superset_views(silver_catalog)\n",
    "        \n",
    "        # 7. V√©rifier la qualit√©\n",
    "        quality_ok = run_gold_data_quality_checks(silver_catalog)\n",
    "        \n",
    "        # 8. Rapport final\n",
    "        end_time = time.time()\n",
    "        duration_seconds = end_time - start_time\n",
    "        duration_minutes = int(duration_seconds // 60)\n",
    "        duration_seconds_remainder = int(duration_seconds % 60)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä RAPPORT FINAL - GOLD LAYER\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\n‚úÖ PIPELINE GOLD TERMIN√â AVEC SUCC√àS!\")\n",
    "        print(f\"‚è±Ô∏è  Dur√©e totale: {duration_minutes} minutes et {duration_seconds_remainder} secondes\")\n",
    "        print(f\"üìÅ Catalogue utilis√©: {silver_catalog}\")\n",
    "        \n",
    "        print(\"\\nüìà TABLES CR√â√âES:\")\n",
    "        print(f\"   ‚Ä¢ daily_metrics: {daily_metrics.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ hourly_patterns: {hourly_patterns.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ top_routes: {top_routes.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ driver_performance: {driver_performance.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ ml_dataset: {ml_dataset.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ ml_fare_prediction: {fare_df.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ ml_duration_prediction: {duration_df.count():,} lignes\")\n",
    "        print(f\"   ‚Ä¢ ml_tip_prediction: {tip_df.count():,} lignes\")\n",
    "        \n",
    "        print(\"\\nüéØ QUALIT√â DES DONN√âES:\")\n",
    "        print(f\"   ‚úÖ Tables Gold v√©rifi√©es: 6/6\")\n",
    "        \n",
    "        print(\"\\nüìä TABLES DASHBOARD CR√â√âES:\")\n",
    "        print(\"   ‚Ä¢ executive_dashboard\")\n",
    "        print(\"   ‚Ä¢ hourly_analysis\")\n",
    "        print(\"   ‚Ä¢ driver_analytics\")\n",
    "        print(\"   ‚Ä¢ weather_dashboard\")\n",
    "        print(\"   ‚Ä¢ route_analysis\")\n",
    "        print(\"   ‚Ä¢ payment_dashboard\")\n",
    "        \n",
    "        print(\"\\n‚ú® PR√äT POUR L'ANALYSE AVANC√âE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Vous pouvez maintenant:\")\n",
    "        print(\"1. Explorer les tables Gold avec SQL\")\n",
    "        print(\"2. Cr√©er des dashboards avec les tables dashboard\")\n",
    "        print(\"3. Entra√Æner des mod√®les ML avec les datasets pr√©par√©s\")\n",
    "        print(\"4. Analyser les performances des conducteurs\")\n",
    "        print(\"5. √âtudier l'impact de la m√©t√©o sur les trajets\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERREUR lors de l'ex√©cution du pipeline Gold: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb416529-ef30-4d87-96f4-b99bf7e5be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EX√âCUTION PRINCIPALE\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Ex√©cuter le pipeline\n",
    "    main()\n",
    "    \n",
    "    print(f\"\\n‚ú® Pr√™t pour l'analyse avanc√©e! Vous pouvez maintenant:\")\n",
    "    print(\"   1. Explorer les tables Gold avec SQL\")\n",
    "    print(\"   2. Connecter Superset aux vues cr√©√©es\")\n",
    "    print(\"   3. Lancer des mod√®les ML sur les datasets pr√©par√©s\")\n",
    "    print(\"   4. Analyser les m√©triques business dans les dashboards\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
