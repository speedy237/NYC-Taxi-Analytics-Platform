{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e156b8b-2f66-413b-b942-6ae4ce643a99",
   "metadata": {},
   "source": [
    " # Machine Learning en Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028d75e-c1d8-42b3-9b3f-f90971a6293e",
   "metadata": {},
   "source": [
    "## Probl√®me 1: Pr√©diction du Prix de la Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505ec8ac-2a28-431c-a75a-2aceb9c41cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/07_ml_price_prediction.py\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, VectorAssembler, \n",
    "    StandardScaler, Imputer\n",
    ")\n",
    "from pyspark.ml.regression import (\n",
    "    RandomForestRegressor, GBTRegressor, LinearRegression\n",
    ")\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def train_price_prediction_model():\n",
    "    \"\"\"Entra√Æne un mod√®le pour pr√©dire le prix des courses\"\"\"\n",
    "    \n",
    "    # Chargement des donn√©es\n",
    "    ml_df = spark.table(\"local.gold.ml_trip_features_sample\") \\\n",
    "                .filter(F.col(\"total_amount\").isNotNull() &\n",
    "                       (F.col(\"total_amount\") > 1) &\n",
    "                       (F.col(\"total_amount\") < 200))\n",
    "    \n",
    "    print(f\"Dataset ML charg√©: {ml_df.count()} lignes\")\n",
    "    \n",
    "    # Split train/test\n",
    "    train_df, test_df = ml_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    # Pr√©processing des features\n",
    "    # 1. Imputation des valeurs manquantes\n",
    "    numeric_cols = [\"trip_distance\", \"real_distance_miles\", \"temp\", \n",
    "                    \"passenger_count\", \"recent_trips_in_zone\"]\n",
    "    \n",
    "    imputer = Imputer(\n",
    "        inputCols=numeric_cols,\n",
    "        outputCols=[f\"{col}_imputed\" for col in numeric_cols],\n",
    "        strategy=\"median\"\n",
    "    )\n",
    "    \n",
    "    # 2. Indexation des colonnes cat√©gorielles\n",
    "    categorical_cols = [\"pickup_borough\", \"dropoff_borough\", \n",
    "                       \"hour_of_day\", \"pickup_day_of_week\"]\n",
    "    \n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=f\"{col}_index\", \n",
    "                      handleInvalid=\"keep\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "    \n",
    "    # 3. One-Hot Encoding\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCols=[f\"{col}_index\" for col in categorical_cols],\n",
    "        outputCols=[f\"{col}_vec\" for col in categorical_cols]\n",
    "    )\n",
    "    \n",
    "    # 4. Assemblage des features\n",
    "    feature_cols = [f\"{col}_imputed\" for col in numeric_cols] + \\\n",
    "                  [f\"{col}_vec\" for col in categorical_cols] + \\\n",
    "                  [\"is_weekend\", \"is_airport_trip\", \"is_manhattan_trip\"]\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_cols,\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "    \n",
    "    # 5. Normalisation\n",
    "    scaler = StandardScaler(\n",
    "        inputCol=\"features\",\n",
    "        outputCol=\"scaled_features\",\n",
    "        withStd=True,\n",
    "        withMean=True\n",
    "    )\n",
    "    \n",
    "    # 6. Mod√®le Random Forest\n",
    "    rf = RandomForestRegressor(\n",
    "        featuresCol=\"scaled_features\",\n",
    "        labelCol=\"total_amount\",\n",
    "        numTrees=100,\n",
    "        maxDepth=10,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Pipeline complet\n",
    "    pipeline = Pipeline(stages=[imputer] + indexers + [encoder, assembler, scaler, rf])\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    print(\"‚è≥ Entra√Ænement du mod√®le Random Forest...\")\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    # √âvaluation\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"total_amount\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    mae_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"total_amount\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"mae\"\n",
    "    )\n",
    "    mae = mae_evaluator.evaluate(predictions)\n",
    "    r2_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"total_amount\", \n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"r2\"\n",
    "    )\n",
    "    r2 = r2_evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le entra√Æn√©!\")\n",
    "    print(f\"üìä Performance du mod√®le:\")\n",
    "    print(f\"   RMSE: ${rmse:.2f}\")\n",
    "    print(f\"   MAE: ${mae:.2f}\")\n",
    "    print(f\"   R¬≤: {r2:.3f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    rf_model = model.stages[-1]\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf_model.featureImportances.toArray()\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüîù Top 10 des features les plus importantes:\")\n",
    "    print(feature_importances.head(10))\n",
    "    \n",
    "    # Sauvegarde du mod√®le\n",
    "    model_path = \"/home/iceberg/models/price_prediction_rf\"\n",
    "    model.write().overwrite().save(model_path)\n",
    "    print(f\"üíæ Mod√®le sauvegard√©: {model_path}\")\n",
    "    \n",
    "    # Pr√©dictions sur l'ensemble de test pour analyse\n",
    "    predictions.select(\"total_amount\", \"prediction\", \"trip_distance\") \\\n",
    "               .writeTo(\"local.gold.ml_price_predictions\") \\\n",
    "               .createOrReplace()\n",
    "    \n",
    "    return model, predictions, feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c83b4-6468-4c06-93e2-4898f8118eeb",
   "metadata": {},
   "source": [
    "## Probl√®me 2: Pr√©diction de la Dur√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62503391-b636-445d-af0d-3058d14c926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_duration_prediction_model():\n",
    "    \"\"\"Entra√Æne un mod√®le pour pr√©dire la dur√©e des courses\"\"\"\n",
    "    \n",
    "    # Chargement et pr√©paration des donn√©es\n",
    "    ml_df = spark.table(\"local.gold.ml_trip_features_sample\") \\\n",
    "                .filter(F.col(\"trip_duration_minutes\").isNotNull() &\n",
    "                       (F.col(\"trip_duration_minutes\") > 1) &\n",
    "                       (F.col(\"trip_duration_minutes\") < 120))\n",
    "    \n",
    "    train_df, test_df = ml_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    # Pipeline similaire mais avec dur√©e comme target\n",
    "    # ... (code similaire au pr√©c√©dent)\n",
    "    \n",
    "    print(\"‚úÖ Mod√®le de pr√©diction de dur√©e entra√Æn√©!\")\n",
    "    \n",
    "    return duration_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8f343-ddcd-4dfc-9786-196d6f57d68c",
   "metadata": {},
   "source": [
    "## Probl√®me 3: Classification des Courses Premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6c6f38-8648-4ae3-b7a8-3f4d6f936665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_premium_classification():\n",
    "    \"\"\"Classification binaire: course premium vs standard\"\"\"\n",
    "    \n",
    "    ml_df = spark.table(\"local.gold.ml_trip_features_sample\")\n",
    "    \n",
    "    # D√©finition: premium si > 75√®me percentile\n",
    "    percentile_75 = ml_df.approxQuantile(\"total_amount\", [0.75], 0.01)[0]\n",
    "    \n",
    "    ml_df = ml_df.withColumn(\n",
    "        \"is_premium\",\n",
    "        F.when(F.col(\"total_amount\") > percentile_75, 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    from pyspark.ml.classification import RandomForestClassifier\n",
    "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "    \n",
    "    # Pipeline de classification\n",
    "    # ... (code similaire mais avec classifier)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le de classification premium entra√Æn√©!\")\n",
    "    print(f\"   Seuil premium: ${percentile_75:.2f}\")\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6b3f3-a70c-47e5-9bb6-3c95215c9593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
